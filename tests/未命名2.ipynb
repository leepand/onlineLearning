{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8ce744-8d03-41d9-879c-7f9f98e6eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onlineLearning.learners import LinUCBLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf7ade95-67dc-48ef-9148-bf059b386e85",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'iterids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test\u001b[38;5;241m=\u001b[39m\u001b[43mLinUCBLearner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mLinUCBLearner.__init__\u001b[0;34m(self, alpha, features, history_storage, model_storage, action_storage, recommendation_cls, model_id)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A_inv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterids\u001b[49m():\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(action_id)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'iterids'"
     ]
    }
   ],
   "source": [
    "test=LinUCBLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f78a53bb-bc2f-4f09-ae77-bfce4ba700c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import six\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, Sequence, Optional, cast, Hashable\n",
    "\n",
    "from onlineLearning.statistics import OnlineVariance\n",
    "from onlineLearning.learners.base import Learner, Probs, Info,Context, Action\n",
    "from onlineLearning.pipes import Flatten\n",
    "from onlineLearning.encodings import InteractionsEncoder\n",
    "from onlineLearning.exceptions import BanditException\n",
    "from onlineLearning.storage import Action as Action_cls\n",
    "\n",
    "class LinUCBLearner(Learner):\n",
    "    \"\"\"一个表示预期奖励的Linucb学习器是一个语境(上下文)和行动特征的线性函数。探索是根据置信度上限估计来进行的。\n",
    "    模型的求解采用`Sherman-Morrison formula`计算矩阵的逆，算法建立在 `Chu et al. (2011) LinUCB algorithm`的基础上，\n",
    "    该实现的计算复杂度与特征数呈线性关系.\n",
    "    Remarks:\n",
    "        The Sherman-Morrsion implementation used below is given in long form `here`__.\n",
    "    References:\n",
    "        Chu, Wei, Lihong Li, Lev Reyzin, and Robert Schapire. \"Contextual bandits\n",
    "        with linear payoff functions.\" In Proceedings of the Fourteenth International\n",
    "        Conference on Artificial Intelligence and Statistics, pp. 208-214. JMLR Workshop\n",
    "        and Conference Proceedings, 2011.\n",
    "    __ https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula\n",
    "    __ https://research.navigating-the-edge.net/assets/publications/linucb_alternate_formulation.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha: float = 0.2, \n",
    "                 features: Sequence[str] = [1, 'ax'],\n",
    "                 history_storage=None, \n",
    "                 model_storage=None, \n",
    "                 action_storage=None,\n",
    "                 recommendation_cls=None,\n",
    "                 model_id=None) -> None:\n",
    "        \"\"\"Instantiate a LinUCBLearner.\n",
    "        Args:\n",
    "            alpha: This parameter controls the exploration rate of the algorithm. A value of 0 will cause actions\n",
    "                to be selected based on the current best point estimate (i.e., no exploration) while a value of inf\n",
    "                means that actions will be selected based solely on the bounds of the action point estimates (i.e.,\n",
    "                we will always take actions that have the largest bound on their point estimate).\n",
    "            features: Feature set interactions to use when calculating action value estimates. Context features\n",
    "                are indicated by x's while action features are indicated by a's. For example, xaa means to cross the\n",
    "                features between context and actions and actions.\n",
    "        \"\"\"\n",
    "        #PackageChecker.numpy(\"LinUCBLearner.__init__\")\n",
    "        super(LinUCBLearner, self).__init__(history_storage, model_storage,\n",
    "                                     action_storage, recommendation_cls)\n",
    "\n",
    "        self._alpha = alpha\n",
    "\n",
    "        self._X = features\n",
    "        self._model_id = model_id\n",
    "        self._X_encoder = InteractionsEncoder(features)\n",
    "\n",
    "    def init_action_model(self, action_list,context=[], model_id = None):\n",
    "\n",
    "        _action_list =[Action_cls(action) for action in action_list]\n",
    "        self._action_storage.add(_action_list)\n",
    "        model = self._model_storage.get_model(model_id)\n",
    "        save_model=0\n",
    "        save_model_param=0\n",
    "\n",
    "        if model is None:\n",
    "            model = {'A_inv': {}, 'theta': {}, 'action_tries':{}}\n",
    "            _A_inv = {}\n",
    "            _theta = {}\n",
    "            _action_tries = {}\n",
    "            save_model = 1\n",
    "        else:\n",
    "            _A_inv = model.get('A_inv')  # pylint: disable=invalid-name\n",
    "            _theta = model.get('theta')\n",
    "            _action_tries = model.get('action_tries')\n",
    "            if _A_inv is None:\n",
    "                _A_inv  = {}\n",
    "                _theta = {}\n",
    "                _action_tries = {}\n",
    "\n",
    "        action_wgt = None\n",
    "        for _action_id in _action_list:\n",
    "            action_id = _action_id.id\n",
    "            if isinstance(context, dict):\n",
    "                _action_wgt = action_wgt.get(action_id,None)\n",
    "                action_context = np.array([self._X_encoder.encode(x=context[action_id],a=_action_wgt)]).T\n",
    "            else:\n",
    "                if action_wgt is None:\n",
    "                    _action_wgt = 1\n",
    "                else:\n",
    "                    _action_wgt = action_wgt.get(action_id,None)\n",
    "                action_context = np.array([self._X_encoder.encode(x=context,a=_action_wgt)]).T\n",
    "\n",
    "            if(_A_inv.get(action_id) is None):\n",
    "                _theta[action_id] = np.zeros((action_context.shape[0],1))\n",
    "                _A_inv[action_id] = np.identity(action_context.shape[0])\n",
    "                _action_tries[action_id] = 0\n",
    "                model[\"A_inv\"][action_id] = _A_inv[action_id]\n",
    "                model[\"theta\"][action_id] = _theta[action_id]\n",
    "                model[\"action_tries\"][action_id] = _action_tries[action_id]\n",
    "                \n",
    "                save_model_param = 1\n",
    "\n",
    "        if save_model==1 or save_model_param==1:\n",
    "            self._model_storage.save_model(model_id=model_id,model=model)\n",
    "            \n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def params(self) -> Dict[str, Any]:\n",
    "        return {'family': 'LinUCB', \n",
    "                'alpha': self._alpha, \n",
    "                'features': self._X,\n",
    "                'model_id':self._model_id}\n",
    "\n",
    "    def _increment_action_tries(self, action: str,model_id: str) -> None:\n",
    "        # 记录曝光，以便给曝光的action（不反馈的情况）降权\n",
    "        model = self._model_storage.get_model(model_id)\n",
    "        _action_tries = model.get('action_tries')\n",
    "        if _action_tries is None:\n",
    "            _action_tries = 0\n",
    "        else:\n",
    "            _action_tries+=1\n",
    "        model[\"action_tries\"] =  _action_tries\n",
    "\n",
    "        self._model_storage.save_model(model_id=model_id,model=model)\n",
    "\n",
    "    def _linucb_score(self, context,action_wgt=None, model_id=None):\n",
    "        \"\"\"disjoint LINUCB algorithm.\n",
    "        \"\"\"\n",
    "        import numpy as np #type: ignore\n",
    "\n",
    "        model = self._model_storage.get_model(model_id)\n",
    "        save_model=0\n",
    "        save_model_param=0\n",
    "        if model is None:\n",
    "            model = {'A_inv': {}, 'theta': {}, 'action_tries':{}}\n",
    "            _A_inv = {}\n",
    "            _theta = {}\n",
    "            _action_tries = {}\n",
    "            save_model = 1\n",
    "        else:\n",
    "            _A_inv = model.get('A_inv')  # pylint: disable=invalid-name\n",
    "            _theta = model.get('theta')\n",
    "            _action_tries = model.get('action_tries')\n",
    "            if _A_inv is None:\n",
    "                _A_inv  = {}\n",
    "                _theta = {}\n",
    "                _action_tries = {}\n",
    "\n",
    "        # The recommended actions should maximize the Linear UCB.\n",
    "        r = {}\n",
    "        p = {}\n",
    "        uncertainty = {}\n",
    "        for action_id in self._action_storage.iterids():\n",
    "\n",
    "            if action_wgt is None:\n",
    "                _action_wgt = 1\n",
    "            else:\n",
    "                _action_wgt = action_wgt.get(action_id,None)\n",
    "\n",
    "            # context可以是dict或list，\n",
    "            if context is None:\n",
    "                self._X_encoder = InteractionsEncoder(\n",
    "                    list(\n",
    "                        set(\n",
    "                            filter(\n",
    "                                None,[ f.replace('x','') if isinstance(f,str) \n",
    "                                      else f for f in self._X ]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                action_context = np.array([self._X_encoder.encode(x=context,a=_action_wgt)]).T\n",
    "            if isinstance(context, dict):\n",
    "                #_action_wgt = action_wgt.get(action_id,None)\n",
    "                action_context = np.array([self._X_encoder.encode(x=context[action_id],a=_action_wgt)]).T\n",
    "            else:\n",
    "                # Reshape covariates input into (d x 1) shape vector\n",
    "                action_context = np.array([self._X_encoder.encode(x=context,a=_action_wgt)]).T\n",
    "\n",
    "            if(_A_inv.get(action_id) is None):\n",
    "                _theta[action_id] = np.zeros((action_context.shape[0],1))\n",
    "                _A_inv[action_id] = np.identity(action_context.shape[0])\n",
    "                _action_tries[action_id] = 0\n",
    "                model[\"A_inv\"][action_id] = _A_inv[action_id]\n",
    "                model[\"theta\"][action_id] = _theta[action_id]\n",
    "                model[\"action_tries\"][action_id] = _action_tries[action_id]\n",
    "                \n",
    "                save_model_param = 1\n",
    "\n",
    "            r[action_id] = float(_theta[action_id].T @ action_context)\n",
    "            #w = float(np.diagonal(action_context.T @ _A_inv[action_id] @ action_context))\n",
    "            w = _A_inv[action_id]@ action_context\n",
    "            v = float(action_context.T@ w)\n",
    "            uncertainty[action_id] = float(self._alpha*np.sqrt(v))\n",
    "            # Find ucb based on p formulation (mean + std_dev) \n",
    "            # p is (1 x 1) dimension vector, use float transfer to single value\n",
    "            p[action_id] = r[action_id]+ uncertainty[action_id]\n",
    "        \n",
    "            #uncertainty[action_id] = float(self._alpha*np.sqrt(point_bounds))\n",
    "\n",
    "            #score[action_id] = estimated_reward[action_id] + uncertainty[action_id]\n",
    "\n",
    "        if save_model==1 or save_model_param==1:\n",
    "            print(\"save_model_param\",model)\n",
    "            self._model_storage.save_model(model_id=model_id,model=model)\n",
    "\n",
    "        return r, uncertainty, p\n",
    "\n",
    "    def _get_action_with_empty_action_storage(self, context, n_actions):\n",
    "        if n_actions is None:\n",
    "            recommendations = None\n",
    "        else:\n",
    "            recommendations = []\n",
    "        history_id = self._history_storage.add_history(context,\n",
    "                                                       recommendations)\n",
    "        return history_id, recommendations\n",
    "\n",
    "    def predict(self, context: Context, \n",
    "                actions: Sequence[Action],\n",
    "                n_actions=None,\n",
    "                request_id=None,\n",
    "                model_id = None) -> Probs:\n",
    "        \"\"\"Return the action to perform\n",
    "        Parameters\n",
    "        ----------\n",
    "        context : dict\n",
    "            Contexts {action_id: context} or [context] of different actions.\n",
    "        n_actions: int (default: None)\n",
    "            Number of actions wanted to recommend users. If None, only return\n",
    "            one action. If -1, get all actions.\n",
    "        Returns\n",
    "        -------\n",
    "        history_id : int\n",
    "            The history id of the action.\n",
    "        recommendations : list of dict\n",
    "            Each dict contains\n",
    "            {Action object, estimated_reward, uncertainty}.\n",
    "        \"\"\"\n",
    "        if self._action_storage.count() == 0:\n",
    "            return self._get_action_with_empty_action_storage(context,\n",
    "                                                              n_actions)\n",
    "\n",
    "        if n_actions == -1:\n",
    "            n_actions = self._action_storage.count()\n",
    "\n",
    "        estimated_reward, uncertainty, score = self._linucb_score(context,actions,model_id)\n",
    "        \n",
    "        if n_actions is None:\n",
    "            recommendation_id = max(score, key=score.get)\n",
    "            recommendations = [self._recommendation_cls(\n",
    "                action=self._action_storage.get(recommendation_id),\n",
    "                estimated_reward=estimated_reward[recommendation_id],\n",
    "                uncertainty=uncertainty[recommendation_id],\n",
    "                score=score[recommendation_id],\n",
    "            )]\n",
    "        else:\n",
    "            recommendation_ids = sorted(score, key=score.get,\n",
    "                                        reverse=True)[:n_actions]\n",
    "            recommendations = []  # pylint: disable=redefined-variable-type\n",
    "            for action_id in recommendation_ids:\n",
    "                recommendations.append(self._recommendation_cls(\n",
    "                    action=self._action_storage.get(action_id),\n",
    "                    estimated_reward=estimated_reward[action_id],\n",
    "                    uncertainty=uncertainty[action_id],\n",
    "                    score=score[action_id],\n",
    "                ))\n",
    "\n",
    "        history_id = self._history_storage.add_history(context=context,\n",
    "                                                       recommendations=recommendations,\n",
    "                                                       request_id=request_id, \n",
    "                                                       model_id=model_id)\n",
    "        #_increment_action_tries(self, action: str,model_id: str)\n",
    "        return recommendations\n",
    "\n",
    "    def learn(self, history_id, rewards,model_id=None) -> None:\n",
    "        \"\"\"Reward the previous action with reward.\n",
    "        Parameters\n",
    "        ----------\n",
    "        history_id : int\n",
    "            The history id of the action to reward.\n",
    "        rewards : dictionary\n",
    "            The dictionary {action_id, reward}, where reward is a float.\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        _context = (self._history_storage\n",
    "                   .get_unrewarded_history(history_id,model_id)\n",
    "                   .context)\n",
    "        \n",
    "        #context = list(Flatten().filter([list(context)]))[0] if context else [] \n",
    "        #features: np.ndarray = np.array(self._X_encoder.encode(x=context,a=action)).T\n",
    "        # Update the model\n",
    "        model = self._model_storage.get_model(model_id)\n",
    "        _A_inv = model[\"A_inv\"]\n",
    "        _theta = model[\"theta\"]\n",
    "        _action_tries = model.get('action_tries')\n",
    "\n",
    "        for action_id, reward in six.viewitems(rewards):\n",
    "            if isinstance(_context, dict):\n",
    "                # Reshape covariates input into (d x 1) shape vector\n",
    "                action_context = np.array([self._X_encoder.encode(x=_context[action_id],a=1)]).T\n",
    "            else:\n",
    "                #对于所有的action_id均一样\n",
    "                action_context = np.array([self._X_encoder.encode(x=_context ,a=1)]).T\n",
    "\n",
    "            r = float(_theta[action_id].T @ action_context)\n",
    "            w = _A_inv[action_id] @ action_context\n",
    "\n",
    "            v = float(action_context.T @ w)\n",
    "\n",
    "            # Find A inverse for ridge regression(use Sherman-Morrison Matrix Inverse Update)\n",
    "            _A_inv[action_id] = _A_inv[action_id] - np.outer(w,w)/(1+v)\n",
    "            print (v,\"ff\",((reward-r)/(1+v)),\"d\",w)\n",
    "            _theta[action_id] = _theta[action_id] + w.dot((reward-r)/(1+v))\n",
    "            \n",
    "        print({\n",
    "            'A_inv': _A_inv,\n",
    "            'theta': _theta,\n",
    "            'action_tries': _action_tries\n",
    "        })\n",
    "        self._model_storage.save_model(model_id=model_id,model={\n",
    "            'A_inv': _A_inv,\n",
    "            'theta': _theta,\n",
    "            'action_tries': _action_tries\n",
    "        })\n",
    "\n",
    "        # Update the history\n",
    "        self._history_storage.add_reward(history_id, rewards, model_id)\n",
    "\n",
    "    def get_models(self,model_id):\n",
    "        model = self._model_storage.get_model(model_id)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e0c5f235-8efc-446e-8d68-98e4bd1407af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamingbandit import simulation\n",
    "from streamingbandit.storage import (\n",
    "    MemoryHistoryStorage,\n",
    "    MemoryModelStorage,\n",
    "    MemoryActionStorage,\n",
    "    Action,\n",
    "    RedisHistoryStorage,\n",
    "    DiskCacheHistoryStorage,\n",
    "    RedisModelStorage\n",
    ")\n",
    "from streamingbandit.bandit import LinUCB\n",
    "\n",
    "\n",
    "context_dimension = 15\n",
    "action_storage = MemoryActionStorage()\n",
    "#action_storage.add([Action(i) for i in range(20)])\n",
    "y=\"/Users/leepand/Downloads/player_ds_platform/full_stack/mlops-project/online-mab/onlineLearning/tests/db\"\n",
    "test=LinUCBLearner(action_storage = action_storage,\n",
    "                   history_storage= DiskCacheHistoryStorage(y),\n",
    "                   model_storage=MemoryModelStorage(), model_id=\"onlinemodel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f732bac7-6e87-4ce4-ae30-d07854c49efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leepand/Downloads/player_ds_platform/full_stack/mlops-project/online-mab/onlineLearning/tests\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "89e04ca4-58b7-4677-ae53-4e5193b9d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family': 'LinUCB',\n",
       " 'alpha': 0.2,\n",
       " 'features': [1, 'a', 'ax'],\n",
       " 'model_id': 'onlinemodel1'}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "69ac50ab-a344-466c-bff4-488a25d58c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.init_action_model([1,2,3],[1,1,1],\"onlinemodel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b431720c-25ae-4620-a472-c8ad13b952c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A_inv': {1: array([[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]]),\n",
       "  2: array([[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]]),\n",
       "  3: array([[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]])},\n",
       " 'theta': {1: array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       "  2: array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]),\n",
       "  3: array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]])},\n",
       " 'action_tries': {1: 0, 2: 0, 3: 0}}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get_models(\"onlinemodel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "02c6c27e-da19-4d70-9d01-2c1319458795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 0.0, 2: 0.0, 3: 0.0},\n",
       " {1: 0.5291502622129182, 2: 0.5291502622129182, 3: 0.5291502622129182},\n",
       " {1: 0.5291502622129182, 2: 0.5291502622129182, 3: 0.5291502622129182})"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._linucb_score([1,2,1],model_id = \"onlinemodel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b4368b98-d38e-443e-a16d-8057d56584d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1: 0.0, 2: 0.0, 3: 0.5294117647058824},\n",
       " {1: 0.5656854249492381, 2: 0.8, 3: 0.29901800063856077},\n",
       " {1: 0.5656854249492381, 2: 0.8, 3: 0.8284297653444431})"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test._linucb_score({1:[1,2,1],\n",
    "                   2:[1,2,3],\n",
    "                   3:[0,2,1]},model_id = \"onlinemodel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "c4234380-9347-4133-9219-2edcf3a8d72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.56 ms, sys: 5.84 ms, total: 9.4 ms\n",
      "Wall time: 10.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recommendation = test.predict([1,2,3],actions=None,request_id=\"2\",model_id = \"onlinemodel1\",n_actions=1)\n",
    "\n",
    "rec = [i.action.id for i in recommendation]\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "dc6f68ba-f7ee-486a-8904-32922e9bb70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 822 µs, sys: 209 µs, total: 1.03 ms\n",
      "Wall time: 946 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 1, 2]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recommendation = test.predict([1,2,3],actions=None,model_id = \"onlinemodel1\",n_actions=3)\n",
    "\n",
    "rec = [i.action.id for i in recommendation]\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "13b824e4-1495-42d2-b830-e0e02b3144d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4838709677419355 ff 0.02173913043478274 d [[0.03225806]\n",
      " [0.03225806]\n",
      " [0.06451613]\n",
      " [0.09677419]]\n",
      "{'A_inv': {1: array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]]), 2: array([[1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1.]]), 3: array([[ 0.93478261, -0.06521739, -0.13043478, -0.19565217],\n",
      "       [-0.06521739,  0.93478261, -0.13043478, -0.19565217],\n",
      "       [-0.13043478, -0.13043478,  0.73913043, -0.39130435],\n",
      "       [-0.19565217, -0.19565217, -0.39130435,  0.41304348]])}, 'theta': {1: array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 2: array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 3: array([[0.06521739],\n",
      "       [0.06521739],\n",
      "       [0.13043478],\n",
      "       [0.19565217]])}, 'action_tries': {1: 0, 2: 0, 3: 0}}\n"
     ]
    }
   ],
   "source": [
    "test.learn(\"2\",{3:1},\"onlinemodel1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91ca081a-7068-409d-994e-fa56bb4422a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<onlineLearning.encodings.InteractionsEncoder object at 0x107899640>\n"
     ]
    }
   ],
   "source": [
    "test.predict(None,[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e93b7514-1c09-4000-9afc-b286a7234d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = [1, 'a', 'ax']\n",
    "uu = InteractionsEncoder(list(set(filter(None,[ f.replace('x','') if \n",
    "                                          isinstance(f,str) else f for f in _X ]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fc2d3c4-d391-4c13-9aec-f87f34bca8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([uu.encode(x=None,a=1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad34dd-213c-4966-a43b-fcbb03ea6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "        if not context:\n",
    "            self._X_encoder = InteractionsEncoder(list(set(filter(None,[ f.replace('x','') if isinstance(f,str) else f for f in self._X ]))))\n",
    "            print(self._X_encoder)\n",
    "            \n",
    "        context = list(Flatten().filter([list(context)]))[0] if context else []\n",
    "        features: np.ndarray = np.array([self._X_encoder.encode(x=context,a=action)]).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
